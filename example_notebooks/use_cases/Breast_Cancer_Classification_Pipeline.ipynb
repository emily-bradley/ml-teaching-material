{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "1) ID number\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "c) perimeter\n",
    "d) area\n",
    "e) smoothness (local variation in radius lengths)\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "h) concave points (number of concave portions of the contour)\n",
    "i) symmetry\n",
    "j) fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the parameters for the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bc_classification_grid_search_object.joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'published_in': 'Electronic imaging', 'year': 1993, 'url': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'doi': '10.1117/12.148698'}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}\n",
      "                  name     role         type demographic description units  \\\n",
      "0                   ID       ID  Categorical        None        None  None   \n",
      "1            Diagnosis   Target  Categorical        None        None  None   \n",
      "2              radius1  Feature   Continuous        None        None  None   \n",
      "3             texture1  Feature   Continuous        None        None  None   \n",
      "4           perimeter1  Feature   Continuous        None        None  None   \n",
      "5                area1  Feature   Continuous        None        None  None   \n",
      "6          smoothness1  Feature   Continuous        None        None  None   \n",
      "7         compactness1  Feature   Continuous        None        None  None   \n",
      "8           concavity1  Feature   Continuous        None        None  None   \n",
      "9      concave_points1  Feature   Continuous        None        None  None   \n",
      "10           symmetry1  Feature   Continuous        None        None  None   \n",
      "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
      "12             radius2  Feature   Continuous        None        None  None   \n",
      "13            texture2  Feature   Continuous        None        None  None   \n",
      "14          perimeter2  Feature   Continuous        None        None  None   \n",
      "15               area2  Feature   Continuous        None        None  None   \n",
      "16         smoothness2  Feature   Continuous        None        None  None   \n",
      "17        compactness2  Feature   Continuous        None        None  None   \n",
      "18          concavity2  Feature   Continuous        None        None  None   \n",
      "19     concave_points2  Feature   Continuous        None        None  None   \n",
      "20           symmetry2  Feature   Continuous        None        None  None   \n",
      "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
      "22             radius3  Feature   Continuous        None        None  None   \n",
      "23            texture3  Feature   Continuous        None        None  None   \n",
      "24          perimeter3  Feature   Continuous        None        None  None   \n",
      "25               area3  Feature   Continuous        None        None  None   \n",
      "26         smoothness3  Feature   Continuous        None        None  None   \n",
      "27        compactness3  Feature   Continuous        None        None  None   \n",
      "28          concavity3  Feature   Continuous        None        None  None   \n",
      "29     concave_points3  Feature   Continuous        None        None  None   \n",
      "30           symmetry3  Feature   Continuous        None        None  None   \n",
      "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = pd.DataFrame(breast_cancer_wisconsin_diagnostic.data.features)\n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(breast_cancer_wisconsin_diagnostic.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(breast_cancer_wisconsin_diagnostic.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data.csv', names=['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "#                                 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "#                                 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', \n",
    "#                                 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "#                                 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "#                                 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst',\n",
    "#                                 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
    "#                                 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius1               float64\n",
       "texture1              float64\n",
       "perimeter1            float64\n",
       "area1                 float64\n",
       "smoothness1           float64\n",
       "compactness1          float64\n",
       "concavity1            float64\n",
       "concave_points1       float64\n",
       "symmetry1             float64\n",
       "fractal_dimension1    float64\n",
       "radius2               float64\n",
       "texture2              float64\n",
       "perimeter2            float64\n",
       "area2                 float64\n",
       "smoothness2           float64\n",
       "compactness2          float64\n",
       "concavity2            float64\n",
       "concave_points2       float64\n",
       "symmetry2             float64\n",
       "fractal_dimension2    float64\n",
       "radius3               float64\n",
       "texture3              float64\n",
       "perimeter3            float64\n",
       "area3                 float64\n",
       "smoothness3           float64\n",
       "compactness3          float64\n",
       "concavity3            float64\n",
       "concave_points3       float64\n",
       "symmetry3             float64\n",
       "fractal_dimension3    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df['diagnosis']\n",
    "# X = df.drop('diagnosis', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to binary\n",
    "y = (y !='B').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1',\n",
       "       'compactness1', 'concavity1', 'concave_points1', 'symmetry1',\n",
       "       'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2',\n",
       "       'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
       "       'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3',\n",
       "       'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
       "       'symmetry3', 'fractal_dimension3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols='id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1',\n",
    "       'compactness1', 'concavity1', 'concave_points1', 'symmetry1',\n",
    "       'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2',\n",
    "       'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
    "       'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3',\n",
    "       'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
    "       'symmetry3', 'fractal_dimension3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing',\n",
    "        ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('scalar imputing mean', SimpleImputer(strategy='mean'), cols),\n",
    "            ], remainder='drop')),\n",
    "#      ,\n",
    "#         ColumnTransformer(\n",
    "#             transformers=[\n",
    "#                 ('scalar scaling', MinMaxScaler(feature_range=(0, 1)))\n",
    "#             ], remainder='drop')),\n",
    "    ('GBT', GradientBoostingClassifier(verbose=1))\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for a grid search over the selected family of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently only contains default values.  Commented parameters needn't be used\n",
    "# in a grid search.\n",
    "dct_grid = {\n",
    "    'GBT__n_estimators' : [100, 250, 350],\n",
    "    'GBT__max_depth'    : [7, 8, 9]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Default values for `GradientBoostingClassifier`.\n",
    "dct_grid = {\n",
    "    'loss'                     : ['deviance'],\n",
    "    'learning_rate'            : [0.1],\n",
    "    'n_estimators'             : [100],\n",
    "    'subsample'                : [1.0],\n",
    "    'criterion'                : ['friedman_mse'],\n",
    "    'min_samples_split'        : [2],\n",
    "    'min_samples_leaf'         : [1],\n",
    "    'min_weight_fraction_leaf' : [0.0],\n",
    "    'max_depth'                : [3],\n",
    "    'min_impurity_decrease'    : [0.0],\n",
    "    'init'                     : [None],\n",
    "    'random_state'             : [None],\n",
    "    'max_features'             : [None],\n",
    "    'verbose'                  : [0],\n",
    "    'max_leaf_nodes'           : [None],\n",
    "    'warm_start'               : [False],\n",
    "    'presort'                  : ['auto'],\n",
    "    'validation_fraction'      : [0.1],\n",
    "    'n_iter_no_change'         : [None],\n",
    "    'tol'                      : [0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilykenney/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1190            0.50s\n",
      "         2           0.9682            0.42s\n",
      "         3           0.8447            0.41s\n",
      "         4           0.7414            0.43s\n",
      "         5           0.6538            0.45s\n",
      "         6           0.5787            0.44s\n",
      "         7           0.5137            0.42s\n",
      "         8           0.4572            0.41s\n",
      "         9           0.4077            0.40s\n",
      "        10           0.3642            0.40s\n",
      "        20           0.1249            0.35s\n",
      "        30           0.0449            0.31s\n",
      "        40           0.0164            0.27s\n",
      "        50           0.0060            0.23s\n",
      "        60           0.0022            0.18s\n",
      "        70           0.0008            0.14s\n",
      "        80           0.0003            0.09s\n",
      "        90           0.0001            0.05s\n",
      "       100           0.0000            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('preprocessing',\n",
       "                                        ColumnTransformer(transformers=[('scalar '\n",
       "                                                                         'imputing '\n",
       "                                                                         'mean',\n",
       "                                                                         SimpleImputer(),\n",
       "                                                                         ['radius1',\n",
       "                                                                          'texture1',\n",
       "                                                                          'perimeter1',\n",
       "                                                                          'area1',\n",
       "                                                                          'smoothness1',\n",
       "                                                                          'compactness1',\n",
       "                                                                          'concavity1',\n",
       "                                                                          'concave_points1',\n",
       "                                                                          'symmetry1',\n",
       "                                                                          'fractal_dimension1',\n",
       "                                                                          'radius2',\n",
       "                                                                          'texture2',\n",
       "                                                                          'perimeter2',\n",
       "                                                                          'area2',\n",
       "                                                                          'smoothness2',\n",
       "                                                                          'compactness2',\n",
       "                                                                          'concav...\n",
       "                                                                          'radius3',\n",
       "                                                                          'texture3',\n",
       "                                                                          'perimeter3',\n",
       "                                                                          'area3',\n",
       "                                                                          'smoothness3',\n",
       "                                                                          'compactness3',\n",
       "                                                                          'concavity3',\n",
       "                                                                          'concave_points3',\n",
       "                                                                          'symmetry3',\n",
       "                                                                          'fractal_dimension3'])])),\n",
       "                                       ('GBT',\n",
       "                                        GradientBoostingClassifier(verbose=1))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'GBT__max_depth': [7, 8, 9],\n",
       "                         'GBT__n_estimators': [100, 250, 350]},\n",
       "             refit='accuracy',\n",
       "             scoring=['accuracy', 'precision', 'average_precision',\n",
       "                      'neg_log_loss'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, dct_grid, cv=10, return_train_score=False\n",
    "                   , scoring=['accuracy', 'precision', 'average_precision', 'neg_log_loss']\n",
    "                   , refit='accuracy', n_jobs=-1 \n",
    "                  )\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time of Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.614556\n",
       "1    1.536062\n",
       "2    2.097075\n",
       "3    0.647201\n",
       "4    1.588529\n",
       "5    2.144267\n",
       "6    0.662922\n",
       "7    1.640785\n",
       "8    1.836546\n",
       "Name: mean_fit_time, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)['mean_fit_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time of run in hours: 0.03546651224295298\n",
      "hours per record: 1.773325612147649e-06\n",
      "number of records in 1 hour 563912.2297393057\n"
     ]
    }
   ],
   "source": [
    "time_of_run_in_hours = (pd.DataFrame(grid_search.cv_results_)['mean_fit_time'] * 10).sum() / 60 / 60\n",
    "print('time of run in hours: {}'.format(time_of_run_in_hours))\n",
    "hours_per_record = time_of_run_in_hours / 20000\n",
    "print('hours per record: {}'.format(hours_per_record))\n",
    "records_in_an_hour = 1 / hours_per_record\n",
    "print('number of records in 1 hour {}'.format(records_in_an_hour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.915115\n",
       "1    0.917996\n",
       "2    0.906755\n",
       "3    0.915718\n",
       "4    0.919277\n",
       "5    0.908521\n",
       "6    0.912262\n",
       "7    0.918599\n",
       "8    0.921433\n",
       "Name: mean_test_average_precision, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)['mean_test_average_precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(grid_sesarch.cv_results_).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('scalar imputing mean',\n",
       "                                                  SimpleImputer(),\n",
       "                                                  ['radius1', 'texture1',\n",
       "                                                   'perimeter1', 'area1',\n",
       "                                                   'smoothness1',\n",
       "                                                   'compactness1', 'concavity1',\n",
       "                                                   'concave_points1',\n",
       "                                                   'symmetry1',\n",
       "                                                   'fractal_dimension1',\n",
       "                                                   'radius2', 'texture2',\n",
       "                                                   'perimeter2', 'area2',\n",
       "                                                   'smoothness2',\n",
       "                                                   'compactness2', 'concavity2',\n",
       "                                                   'concave_points2',\n",
       "                                                   'symmetry2',\n",
       "                                                   'fractal_dimension2',\n",
       "                                                   'radius3', 'texture3',\n",
       "                                                   'perimeter3', 'area3',\n",
       "                                                   'smoothness3',\n",
       "                                                   'compactness3', 'concavity3',\n",
       "                                                   'concave_points3',\n",
       "                                                   'symmetry3',\n",
       "                                                   'fractal_dimension3'])])),\n",
       "                ('GBT', GradientBoostingClassifier(max_depth=9, verbose=1))])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.614556</td>\n",
       "      <td>1.536062</td>\n",
       "      <td>2.097075</td>\n",
       "      <td>0.647201</td>\n",
       "      <td>1.588529</td>\n",
       "      <td>2.144267</td>\n",
       "      <td>0.662922</td>\n",
       "      <td>1.640785</td>\n",
       "      <td>1.836546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_GBT__max_depth</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_GBT__n_estimators</th>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>350</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>350</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <td>0.937115</td>\n",
       "      <td>0.937115</td>\n",
       "      <td>0.937115</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.942115</td>\n",
       "      <td>0.939615</td>\n",
       "      <td>0.939615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_precision</th>\n",
       "      <td>0.9202</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>0.914048</td>\n",
       "      <td>0.914048</td>\n",
       "      <td>0.914048</td>\n",
       "      <td>0.930655</td>\n",
       "      <td>0.924464</td>\n",
       "      <td>0.924464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_average_precision</th>\n",
       "      <td>0.915115</td>\n",
       "      <td>0.917996</td>\n",
       "      <td>0.906755</td>\n",
       "      <td>0.915718</td>\n",
       "      <td>0.919277</td>\n",
       "      <td>0.908521</td>\n",
       "      <td>0.912262</td>\n",
       "      <td>0.918599</td>\n",
       "      <td>0.921433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <td>-0.629262</td>\n",
       "      <td>-1.48841</td>\n",
       "      <td>-1.990283</td>\n",
       "      <td>-0.592485</td>\n",
       "      <td>-1.424668</td>\n",
       "      <td>-1.911735</td>\n",
       "      <td>-0.5688</td>\n",
       "      <td>-1.352895</td>\n",
       "      <td>-1.812718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0         1         2         3         4  \\\n",
       "mean_fit_time                0.614556  1.536062  2.097075  0.647201  1.588529   \n",
       "param_GBT__max_depth                7         7         7         8         8   \n",
       "param_GBT__n_estimators           100       250       350       100       250   \n",
       "mean_test_accuracy           0.937115  0.937115  0.937115  0.934615  0.934615   \n",
       "mean_test_precision            0.9202    0.9202    0.9202  0.914048  0.914048   \n",
       "mean_test_average_precision  0.915115  0.917996  0.906755  0.915718  0.919277   \n",
       "mean_test_neg_log_loss      -0.629262  -1.48841 -1.990283 -0.592485 -1.424668   \n",
       "\n",
       "                                    5         6         7         8  \n",
       "mean_fit_time                2.144267  0.662922  1.640785  1.836546  \n",
       "param_GBT__max_depth                8         9         9         9  \n",
       "param_GBT__n_estimators           350       100       250       350  \n",
       "mean_test_accuracy           0.934615  0.942115  0.939615  0.939615  \n",
       "mean_test_precision          0.914048  0.930655  0.924464  0.924464  \n",
       "mean_test_average_precision  0.908521  0.912262  0.918599  0.921433  \n",
       "mean_test_neg_log_loss      -1.911735   -0.5688 -1.352895 -1.812718  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)[['mean_fit_time', 'param_GBT__max_depth', 'param_GBT__n_estimators',\n",
    "                                      'mean_test_accuracy', 'mean_test_precision', 'mean_test_average_precision',\n",
    "                                      'mean_test_neg_log_loss']].T#.to_csv('model_training_performance_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame({'column': cols,\n",
    "                            'feature_importance': grid_search.best_estimator_.named_steps[\"GBT\"].feature_importances_})\n",
    "feature_imp = feature_imp.sort_values('feature_importance', ascending=False)\n",
    "#feature_imp.to_csv('feature_importance_90k_lapse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave_points_mean</td>\n",
       "      <td>0.712714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>0.078024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>0.076143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>0.043814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>0.017637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>0.011739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.010126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>0.010103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>0.008045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>0.007376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>0.005141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>0.004967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>0.004463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>0.003754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>0.002274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  column  feature_importance\n",
       "7    concave_points_mean            0.712714\n",
       "21         texture_worst            0.078024\n",
       "23            area_worst            0.076143\n",
       "3              area_mean            0.043814\n",
       "26       concavity_worst            0.017637\n",
       "1           texture_mean            0.011739\n",
       "13               area_se            0.010126\n",
       "24      smoothness_worst            0.010103\n",
       "15        compactness_se            0.008045\n",
       "25     compactness_worst            0.007376\n",
       "0            radius_mean            0.005141\n",
       "17     concave points_se            0.004967\n",
       "27  concave points_worst            0.004463\n",
       "11            texture_se            0.003754\n",
       "2         perimeter_mean            0.002274"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump(grid_search, '{}.joblib'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results = pd.DataFrame({'policy_agreement_id': df_train.index,\n",
    "#                         'probability': grid_sesarch.best_estimator_.predict_proba(X_train)[:, 1],\n",
    "#                         'prediction': grid_sesarch.best_estimator_.predict(X_train),\n",
    "#                         'actual': Y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#results.to_csv('results_training_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample (171) performance metrics\n",
      "average precision: 0.9925298187863119\n",
      "log loss: 0.257514191077136\n",
      "accuracy: 0.9473684210526315\n",
      "precision: 0.890625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, log_loss, accuracy_score, precision_score\n",
    "print('Test ({} samples) performance metrics'.format(len(y_test)))\n",
    "print('average precision: {}'.format(average_precision_score(y_test, \n",
    "                                                            grid_search.predict_proba(X_test)[:, 1])))\n",
    "print('log loss: {}'.format(log_loss(y_test, grid_search.predict_proba(X_test)[:, 1])))\n",
    "print('accuracy: {}'.format(accuracy_score(y_test, grid_search.predict(X_test))))\n",
    "print('precision: {}'.format(precision_score(y_test, grid_search.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = pd.DataFrame({'id': X_test['id'],\n",
    "                            'probability': grid_search.predict_proba(X_test)[:, 1],\n",
    "                            'prediction': grid_search.predict(X_test),\n",
    "                             'actual': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0</td>\n",
       "      <td>9112367</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>872608</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0</td>\n",
       "      <td>8913</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>857392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>90769602</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual        id  prediction  probability\n",
       "458       0   9112367           0     0.000140\n",
       "177       0    872608           0     0.000138\n",
       "288       0      8913           0     0.000138\n",
       "54        1    857392           1     0.999775\n",
       "430       0  90769602           0     0.000138"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_scores_with_data = pd.concat([test_scores, X_train.drop('id', axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_scores_with_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_scores_with_data.to_csv('{}_scores_with_data.csv'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predcitions Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458    0\n",
       "177    0\n",
       "288    0\n",
       "54     1\n",
       "430    0\n",
       "429    0\n",
       "159    0\n",
       "75     0\n",
       "201    0\n",
       "522    1\n",
       "369    1\n",
       "166    0\n",
       "517    1\n",
       "48     1\n",
       "273    1\n",
       "202    1\n",
       "9      1\n",
       "361    0\n",
       "454    0\n",
       "131    0\n",
       "503    0\n",
       "85     0\n",
       "483    0\n",
       "172    1\n",
       "5      1\n",
       "469    1\n",
       "252    0\n",
       "558    0\n",
       "196    0\n",
       "338    1\n",
       "      ..\n",
       "542    0\n",
       "249    0\n",
       "471    0\n",
       "518    1\n",
       "524    0\n",
       "263    1\n",
       "547    0\n",
       "26     1\n",
       "478    0\n",
       "199    1\n",
       "383    0\n",
       "485    0\n",
       "155    0\n",
       "105    0\n",
       "258    1\n",
       "114    0\n",
       "236    0\n",
       "521    0\n",
       "530    0\n",
       "345    0\n",
       "230    1\n",
       "49     0\n",
       "541    0\n",
       "460    0\n",
       "22     0\n",
       "157    1\n",
       "203    1\n",
       "145    0\n",
       "101    1\n",
       "227    0\n",
       "Name: actual, Length: 171, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-2af7ba59f2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scores_with_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scores_with_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m     71\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_scores_with_data['actual'], test_scores_with_data['prediction'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[78.49000000000001, 3.27], [5.795, 12.445]]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(out_of_sample_results)\n",
    "perc_vals = [[cm[0][0]/total*100, cm[0][1]/total*100], [cm[1][0]/total*100, cm[1][1]/total*100]]\n",
    "perc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
