{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "1) ID number\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "c) perimeter\n",
    "d) area\n",
    "e) smoothness (local variation in radius lengths)\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "h) concave points (number of concave portions of the contour)\n",
    "i) symmetry\n",
    "j) fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the parameters for the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'bc_classification_grid_search_object.joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', names=['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "                                'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "                                'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', \n",
    "                                'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "                                'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "                                'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst',\n",
    "                                'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
    "                                'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          object\n",
       "diagnosis                   object\n",
       "radius_mean                float64\n",
       "texture_mean               float64\n",
       "perimeter_mean             float64\n",
       "area_mean                  float64\n",
       "smoothness_mean            float64\n",
       "compactness_mean           float64\n",
       "concavity_mean             float64\n",
       "concave_points_mean        float64\n",
       "symmetry_mean              float64\n",
       "fractal_dimension_mean     float64\n",
       "radius_se                  float64\n",
       "texture_se                 float64\n",
       "perimeter_se               float64\n",
       "area_se                    float64\n",
       "smoothness_se              float64\n",
       "compactness_se             float64\n",
       "concavity_se               float64\n",
       "concave points_se          float64\n",
       "symmetry_se                float64\n",
       "fractal_dimension_se       float64\n",
       "radius_worst               float64\n",
       "texture_worst              float64\n",
       "perimeter_worst            float64\n",
       "area_worst                 float64\n",
       "smoothness_worst           float64\n",
       "compactness_worst          float64\n",
       "concavity_worst            float64\n",
       "concave points_worst       float64\n",
       "symmetry_worst             float64\n",
       "fractal_dimension_worst    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['diagnosis']\n",
    "X = df.drop('diagnosis', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = (y !='B').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ignore_cols='id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "        'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "        'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', \n",
    "        'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "        'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "        'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst',\n",
    "        'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
    "        'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing',\n",
    "        ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('scalar imputing mean', SimpleImputer(strategy='mean'), cols),\n",
    "            ], remainder='drop')),\n",
    "#      ,\n",
    "#         ColumnTransformer(\n",
    "#             transformers=[\n",
    "#                 ('scalar scaling', MinMaxScaler(feature_range=(0, 1)))\n",
    "#             ], remainder='drop')),\n",
    "    ('GBT', GradientBoostingClassifier(verbose=1))\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for a grid search over the selected family of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Currently only contains default values.  Commented parameters needn't be used\n",
    "# in a grid search.\n",
    "dct_grid = {\n",
    "    'GBT__n_estimators' : [100, 250, 350],\n",
    "    'GBT__max_depth'    : [7, 8, 9]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Default values for `GradientBoostingClassifier`.\n",
    "dct_grid = {\n",
    "    'loss'                     : ['deviance'],\n",
    "    'learning_rate'            : [0.1],\n",
    "    'n_estimators'             : [100],\n",
    "    'subsample'                : [1.0],\n",
    "    'criterion'                : ['friedman_mse'],\n",
    "    'min_samples_split'        : [2],\n",
    "    'min_samples_leaf'         : [1],\n",
    "    'min_weight_fraction_leaf' : [0.0],\n",
    "    'max_depth'                : [3],\n",
    "    'min_impurity_decrease'    : [0.0],\n",
    "    'init'                     : [None],\n",
    "    'random_state'             : [None],\n",
    "    'max_features'             : [None],\n",
    "    'verbose'                  : [0],\n",
    "    'max_leaf_nodes'           : [None],\n",
    "    'warm_start'               : [False],\n",
    "    'presort'                  : ['auto'],\n",
    "    'validation_fraction'      : [0.1],\n",
    "    'n_iter_no_change'         : [None],\n",
    "    'tol'                      : [0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/req89250/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1439            0.76s\n",
      "         2           0.9915            0.71s\n",
      "         3           0.8659            0.70s\n",
      "         4           0.7606            0.70s\n",
      "         5           0.6710            0.69s\n",
      "         6           0.5940            0.69s\n",
      "         7           0.5274            0.68s\n",
      "         8           0.4695            0.67s\n",
      "         9           0.4187            0.67s\n",
      "        10           0.3741            0.67s\n",
      "        20           0.1283            0.63s\n",
      "        30           0.0461            0.60s\n",
      "        40           0.0168            0.58s\n",
      "        50           0.0062            0.56s\n",
      "        60           0.0023            0.53s\n",
      "        70           0.0009            0.49s\n",
      "        80           0.0005            0.44s\n",
      "        90           0.0004            0.38s\n",
      "       100           0.0004            0.33s\n",
      "       200           0.0004            0.06s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessing',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('scalar '\n",
       "                                                                         'imputing '\n",
       "                                                                         'mean',\n",
       "                                                                         SimpleImputer(add_indicator=False,\n",
       "                                                                                       copy=True,\n",
       "                                                                                       fill_value=None,\n",
       "                                                                                       missing_values=nan,\n",
       "                                                                                       strategy='mean',\n",
       "                                                                                       verbose=0),\n",
       "                                                                         ['rad...\n",
       "                                                                   presort='auto',\n",
       "                                                                   random_state=None,\n",
       "                                                                   subsample=1.0,\n",
       "                                                                   tol=0.0001,\n",
       "                                                                   validation_fraction=0.1,\n",
       "                                                                   verbose=1,\n",
       "                                                                   warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'GBT__max_depth': [7, 8, 9],\n",
       "                         'GBT__n_estimators': [100, 250, 350]},\n",
       "             pre_dispatch='2*n_jobs', refit='accuracy',\n",
       "             return_train_score=False,\n",
       "             scoring=['accuracy', 'precision', 'average_precision',\n",
       "                      'neg_log_loss'],\n",
       "             verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, dct_grid, cv=10, return_train_score=False\n",
    "                   , scoring=['accuracy', 'precision', 'average_precision', 'neg_log_loss']\n",
    "                   , refit='accuracy', n_jobs=-1 \n",
    "                  )\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time of Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.326132\n",
       "1    0.377651\n",
       "2    0.414694\n",
       "3    0.318390\n",
       "4    0.406536\n",
       "5    0.432444\n",
       "6    0.326364\n",
       "7    0.386804\n",
       "8    0.423554\n",
       "Name: mean_fit_time, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)['mean_fit_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time of run in hours: 0.00947935938835144\n",
      "hours per record: 4.7396796941757194e-07\n",
      "number of records in 1 hour 2109847.2144200676\n"
     ]
    }
   ],
   "source": [
    "time_of_run_in_hours = (pd.DataFrame(grid_search.cv_results_)['mean_fit_time'] * 10).sum() / 60 / 60\n",
    "print('time of run in hours: {}'.format(time_of_run_in_hours))\n",
    "hours_per_record = time_of_run_in_hours / 20000\n",
    "print('hours per record: {}'.format(hours_per_record))\n",
    "records_in_an_hour = 1 / hours_per_record\n",
    "print('number of records in 1 hour {}'.format(records_in_an_hour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.972465\n",
       "1    0.974277\n",
       "2    0.973894\n",
       "3    0.972370\n",
       "4    0.973677\n",
       "5    0.974807\n",
       "6    0.971562\n",
       "7    0.971830\n",
       "8    0.971253\n",
       "Name: mean_test_average_precision, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)['mean_test_average_precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(grid_sesarch.cv_results_).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(memory=None,\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('scalar imputing mean',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='mean',\n",
       "                                                                verbose=0),\n",
       "                                                  ['radius_mean',\n",
       "                                                   'texture_mean',\n",
       "                                                   'perimeter_mean',\n",
       "                                                   'area_mean',\n",
       "                                                   'smoothness...\n",
       "                                            learning_rate=0.1, loss='deviance',\n",
       "                                            max_depth=7, max_features=None,\n",
       "                                            max_leaf_nodes=None,\n",
       "                                            min_impurity_decrease=0.0,\n",
       "                                            min_impurity_split=None,\n",
       "                                            min_samples_leaf=1,\n",
       "                                            min_samples_split=2,\n",
       "                                            min_weight_fraction_leaf=0.0,\n",
       "                                            n_estimators=250,\n",
       "                                            n_iter_no_change=None,\n",
       "                                            presort='auto', random_state=None,\n",
       "                                            subsample=1.0, tol=0.0001,\n",
       "                                            validation_fraction=0.1, verbose=1,\n",
       "                                            warm_start=False))],\n",
       "         verbose=False)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.326132</td>\n",
       "      <td>0.377651</td>\n",
       "      <td>0.414694</td>\n",
       "      <td>0.31839</td>\n",
       "      <td>0.406536</td>\n",
       "      <td>0.432444</td>\n",
       "      <td>0.326364</td>\n",
       "      <td>0.386804</td>\n",
       "      <td>0.423554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_GBT__max_depth</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_GBT__n_estimators</th>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>350</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>350</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <td>0.927318</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.927318</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.922306</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.919799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_precision</th>\n",
       "      <td>0.915701</td>\n",
       "      <td>0.917929</td>\n",
       "      <td>0.929802</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>0.914154</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>0.900069</td>\n",
       "      <td>0.888337</td>\n",
       "      <td>0.89941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_average_precision</th>\n",
       "      <td>0.972465</td>\n",
       "      <td>0.974277</td>\n",
       "      <td>0.973894</td>\n",
       "      <td>0.97237</td>\n",
       "      <td>0.973677</td>\n",
       "      <td>0.974807</td>\n",
       "      <td>0.971562</td>\n",
       "      <td>0.97183</td>\n",
       "      <td>0.971253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <td>-0.483263</td>\n",
       "      <td>-0.464406</td>\n",
       "      <td>-0.45439</td>\n",
       "      <td>-0.483334</td>\n",
       "      <td>-0.476228</td>\n",
       "      <td>-0.464766</td>\n",
       "      <td>-0.499751</td>\n",
       "      <td>-0.493519</td>\n",
       "      <td>-0.498142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0         1         2         3         4  \\\n",
       "mean_fit_time                0.326132  0.377651  0.414694   0.31839  0.406536   \n",
       "param_GBT__max_depth                7         7         7         8         8   \n",
       "param_GBT__n_estimators           100       250       350       100       250   \n",
       "mean_test_accuracy           0.927318  0.929825  0.929825  0.924812  0.927318   \n",
       "mean_test_precision          0.915701  0.917929  0.929802    0.9118  0.914154   \n",
       "mean_test_average_precision  0.972465  0.974277  0.973894   0.97237  0.973677   \n",
       "mean_test_neg_log_loss      -0.483263 -0.464406  -0.45439 -0.483334 -0.476228   \n",
       "\n",
       "                                    5         6         7         8  \n",
       "mean_fit_time                0.432444  0.326364  0.386804  0.423554  \n",
       "param_GBT__max_depth                8         9         9         9  \n",
       "param_GBT__n_estimators           350       100       250       350  \n",
       "mean_test_accuracy           0.924812  0.922306  0.912281  0.919799  \n",
       "mean_test_precision            0.9118  0.900069  0.888337   0.89941  \n",
       "mean_test_average_precision  0.974807  0.971562   0.97183  0.971253  \n",
       "mean_test_neg_log_loss      -0.464766 -0.499751 -0.493519 -0.498142  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)[['mean_fit_time', 'param_GBT__max_depth', 'param_GBT__n_estimators',\n",
    "                                      'mean_test_accuracy', 'mean_test_precision', 'mean_test_average_precision',\n",
    "                                      'mean_test_neg_log_loss']].T#.to_csv('model_training_performance_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame({'column': cols,\n",
    "                            'feature_importance': grid_search.best_estimator_.named_steps[\"GBT\"].feature_importances_})\n",
    "feature_imp = feature_imp.sort_values('feature_importance', ascending=False)\n",
    "#feature_imp.to_csv('feature_importance_90k_lapse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave_points_mean</td>\n",
       "      <td>0.712714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>0.078024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>0.076143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>0.043814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>0.017637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>0.011739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.010126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>0.010103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>0.008045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>0.007376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>0.005141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>0.004967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>0.004463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>0.003754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>0.002274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  column  feature_importance\n",
       "7    concave_points_mean            0.712714\n",
       "21         texture_worst            0.078024\n",
       "23            area_worst            0.076143\n",
       "3              area_mean            0.043814\n",
       "26       concavity_worst            0.017637\n",
       "1           texture_mean            0.011739\n",
       "13               area_se            0.010126\n",
       "24      smoothness_worst            0.010103\n",
       "15        compactness_se            0.008045\n",
       "25     compactness_worst            0.007376\n",
       "0            radius_mean            0.005141\n",
       "17     concave points_se            0.004967\n",
       "27  concave points_worst            0.004463\n",
       "11            texture_se            0.003754\n",
       "2         perimeter_mean            0.002274"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump(grid_search, '{}.joblib'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results = pd.DataFrame({'policy_agreement_id': df_train.index,\n",
    "#                         'probability': grid_sesarch.best_estimator_.predict_proba(X_train)[:, 1],\n",
    "#                         'prediction': grid_sesarch.best_estimator_.predict(X_train),\n",
    "#                         'actual': Y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#results.to_csv('results_training_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample (171) performance metrics\n",
      "average precision: 0.9925298187863119\n",
      "log loss: 0.257514191077136\n",
      "accuracy: 0.9473684210526315\n",
      "precision: 0.890625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, log_loss, accuracy_score, precision_score\n",
    "print('Test ({} samples) performance metrics'.format(len(y_test)))\n",
    "print('average precision: {}'.format(average_precision_score(y_test, \n",
    "                                                            grid_search.predict_proba(X_test)[:, 1])))\n",
    "print('log loss: {}'.format(log_loss(y_test, grid_search.predict_proba(X_test)[:, 1])))\n",
    "print('accuracy: {}'.format(accuracy_score(y_test, grid_search.predict(X_test))))\n",
    "print('precision: {}'.format(precision_score(y_test, grid_search.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = pd.DataFrame({'id': X_test['id'],\n",
    "                            'probability': grid_search.predict_proba(X_test)[:, 1],\n",
    "                            'prediction': grid_search.predict(X_test),\n",
    "                             'actual': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0</td>\n",
       "      <td>9112367</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>872608</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0</td>\n",
       "      <td>8913</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>857392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>90769602</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual        id  prediction  probability\n",
       "458       0   9112367           0     0.000140\n",
       "177       0    872608           0     0.000138\n",
       "288       0      8913           0     0.000138\n",
       "54        1    857392           1     0.999775\n",
       "430       0  90769602           0     0.000138"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_scores_with_data = pd.concat([test_scores, X_train.drop('id', axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_scores_with_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_scores_with_data.to_csv('{}_scores_with_data.csv'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predcitions Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458    0\n",
       "177    0\n",
       "288    0\n",
       "54     1\n",
       "430    0\n",
       "429    0\n",
       "159    0\n",
       "75     0\n",
       "201    0\n",
       "522    1\n",
       "369    1\n",
       "166    0\n",
       "517    1\n",
       "48     1\n",
       "273    1\n",
       "202    1\n",
       "9      1\n",
       "361    0\n",
       "454    0\n",
       "131    0\n",
       "503    0\n",
       "85     0\n",
       "483    0\n",
       "172    1\n",
       "5      1\n",
       "469    1\n",
       "252    0\n",
       "558    0\n",
       "196    0\n",
       "338    1\n",
       "      ..\n",
       "542    0\n",
       "249    0\n",
       "471    0\n",
       "518    1\n",
       "524    0\n",
       "263    1\n",
       "547    0\n",
       "26     1\n",
       "478    0\n",
       "199    1\n",
       "383    0\n",
       "485    0\n",
       "155    0\n",
       "105    0\n",
       "258    1\n",
       "114    0\n",
       "236    0\n",
       "521    0\n",
       "530    0\n",
       "345    0\n",
       "230    1\n",
       "49     0\n",
       "541    0\n",
       "460    0\n",
       "22     0\n",
       "157    1\n",
       "203    1\n",
       "145    0\n",
       "101    1\n",
       "227    0\n",
       "Name: actual, Length: 171, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-2af7ba59f2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scores_with_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scores_with_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m     71\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_scores_with_data['actual'], test_scores_with_data['prediction'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[78.49000000000001, 3.27], [5.795, 12.445]]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(out_of_sample_results)\n",
    "perc_vals = [[cm[0][0]/total*100, cm[0][1]/total*100], [cm[1][0]/total*100, cm[1][1]/total*100]]\n",
    "perc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
