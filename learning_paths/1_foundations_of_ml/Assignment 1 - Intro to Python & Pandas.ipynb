{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd45129",
   "metadata": {
    "id": "xbCRG2-uUKCT"
   },
   "source": [
    "## Data for Supervised Learning\n",
    "Supervised learning is all about learning to make predictions: given an input $x$ (e.g. home square footage), can we produce an output $\\hat{y}$ (e.g. estimated value) as close to the actual observed output $y$ (e.g. sale price) as possible. Note that the \"hat\" above $y$ is used to denote an estimated or predicted value.\n",
    "\n",
    "Let's start by generating some artificial data. We'll create a vector of inputs, $X$, and a corresponding vector of target outputs $Y$. In general, we'll refer to invidual examples with a lowercase ($x$), and a vector or matrix containing multiple examples with a capital ($X$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00523db0",
   "metadata": {},
   "source": [
    "### Part 1: Generating a Known Function (15 points)\n",
    "\n",
    "Implement variable Y as:\n",
    "\n",
    "$Y = m*X + b + variance$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289bac4c",
   "metadata": {
    "id": "Ulmn_bFdU87t"
   },
   "outputs": [],
   "source": [
    "def create_1d_data(num_examples=10, m=2, b=1, random_scale=1):\n",
    "    \"\"\"Create X, Y data with a linear relationship with added noise.\n",
    "\n",
    "    Args:\n",
    "    num_examples: number of examples to generate\n",
    "    w: desired slope\n",
    "    b: desired intercept\n",
    "    random_scale: add uniform noise between -random_scale and +random_scale\n",
    "\n",
    "    Returns:\n",
    "    X and Y with shape (num_examples)\n",
    "    \"\"\"\n",
    "    X = np.arange(num_examples)\n",
    "    np.random.seed(4)  # consistent random number generation\n",
    "    random_variance = np.random.uniform(low=-random_scale, high=random_scale, size=X.shape)\n",
    "    # TODO: build Y = mx + b + random_variance\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193d44b",
   "metadata": {
    "id": "6qJg0IiYVJ8U"
   },
   "outputs": [],
   "source": [
    "# Create some artificial data using create_1d_data.\n",
    "X, Y = create_1d_data()\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee64b845",
   "metadata": {},
   "source": [
    "Explain why the graph does not exactly represent 2X+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6880bd4",
   "metadata": {
    "id": "h0Zpx79_aQEC"
   },
   "source": [
    "*Writen answer:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ef8d1",
   "metadata": {
    "id": "W6coKbXSpXOz"
   },
   "source": [
    "---\n",
    "### Part 2: Models for Data (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1591c",
   "metadata": {},
   "source": [
    "A model is a function that takes an input $x$ and produces a prediction $\\hat{y}$.\n",
    "\n",
    "Let's consider two possible models for this data:\n",
    "1. $M_1(x) = x+5$ \n",
    "2. $M_2(x) = 2x+1$\n",
    "\n",
    "Compute the predictions of models $M_1$ and $M_2$ for the values in $X$. These predictions should be vectors of the same shape as $Y$. Then plot the prediction lines of these two models overlayed on the \"observed\" data $(X, Y)$. Use [plt.plot()](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html) to draw the lines. Note: you will generate only one plot. Make sure to include axes, titles and legend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec59302",
   "metadata": {
    "id": "AHIY5kNXUIAP"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y)\n",
    "\n",
    "plt.plot(M1, color = 'r')\n",
    "plt.plot(M2, color = 'g')\n",
    "\n",
    "plt.legend([\"X Observed Data\", \"M1 Model Preds\", \"M2 Model Preds\"], loc=\"lower right\")\n",
    "\n",
    "font1 = {'family':'serif','color':'blue','size':20}\n",
    "font2 = {'family':'serif','color':'darkred','size':15}\n",
    "\n",
    "plt.title(\"Comparison of M1 and M2 Models\", fontdict = font1)\n",
    "plt.xlabel(\"X Input Values\", fontdict = font2)\n",
    "plt.ylabel(\"Y Output Values\", fontdict = font2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b44a24",
   "metadata": {},
   "source": [
    "Explain which model looks to be performing better. How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebd3152",
   "metadata": {
    "id": "h0Zpx79_aQEC"
   },
   "source": [
    "*Writen answer:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a6f35",
   "metadata": {
    "id": "W6coKbXSpXOz"
   },
   "source": [
    "---\n",
    "### Part 3: EDA with Pandas (70 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d2ad74",
   "metadata": {},
   "source": [
    "Import sklearn and pandas and read the iris dataset into a pandas dataframe: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c302f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ebda62",
   "metadata": {},
   "source": [
    "What is the iris dataset? What are we trying to predict? What type of machine learning problem is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b30bd",
   "metadata": {
    "id": "h0Zpx79_aQEC"
   },
   "source": [
    "*Writen answer:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a789a",
   "metadata": {},
   "source": [
    "Explore the data, perform EDA (Exploratory Data Analysis) on the iris dataset. Print the distribution of each feature (variable). Is there any missing data? Print the label classes, counts, and percentages of our target variable. Note any interesting findings. What are your thoughts on how we might measure success on this problem (i.e. a model that predicts the target labels)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23b6a7",
   "metadata": {
    "id": "h0Zpx79_aQEC"
   },
   "source": [
    "*Writen answer:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a3fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d433355",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85b424",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "* In **Supervised Machine Learning**, we must start with data in the form $(X,Y)$ where $X$ are the inputs and $Y$ are the output labels.\n",
    "* A **model** is a function that maps an input $x$ to an output $y$. The model's output is referred to as a **prediction**, denoted by $\\hat{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c532388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
